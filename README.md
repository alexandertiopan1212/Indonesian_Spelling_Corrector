# ğŸ‡®ğŸ‡© Indonesian Spelling Corrector using RNN

This repository contains an implementation of a **character-level spelling correction system** for Indonesian words using a Sequence-to-Sequence **Recurrent Neural Network (RNN)** architecture. The model is trained on a curated dataset of correct root words and learns to map noisy or misspelled inputs into their proper forms.

---

## ğŸ“ Repository Structure

```
ğŸ“¦ Indonesian_Spelling_Corrector
â”œâ”€â”€ spelling_corrector.ipynb     # Main notebook: preprocessing, training, evaluation
â”œâ”€â”€ root_word.txt                # Dataset of 41,000+ root words
â”œâ”€â”€ char_utils.py                # Character-index conversion utils
â”œâ”€â”€ trained_model.h5             # Saved RNN model (optional, after training)
```

---

## ğŸ“Œ Key Features

- ğŸ”¡ Character-level sequence-to-sequence LSTM architecture
- âš™ï¸ Preprocessing includes cleaning, gibberish generation, and one-hot encoding
- ğŸ“ˆ Exploratory Data Analysis (EDA) for character, prefix, suffix, and length distribution
- ğŸ§ª Model trained using categorical crossentropy loss and RMSprop optimizer
- ğŸ“š Easy to extend for online spelling correction or auto-completion

---

## ğŸ›  How to Use

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/Indonesian_Spelling_Corrector.git
   cd Indonesian_Spelling_Corrector
   ```

2. Install dependencies:
   ```bash
   pip install numpy pandas matplotlib seaborn plotly tensorflow
   ```

3. Open and run the notebook:
   ```bash
   jupyter notebook spelling_corrector.ipynb
   ```

---

## ğŸ“Š Dataset

The dataset `root_word.txt` contains more than 41,000 valid Indonesian root words. Synthetic misspellings are generated via a gibberish function that performs random insertions, deletions, and substitutions to simulate real-world typos.

---

## ğŸ§  Model Architecture

- **Encoder**: LSTM layer that processes the noisy input sequence
- **Decoder**: LSTM layer that outputs the corrected word sequence
- **Activation**: Softmax on decoder output
- **Loss Function**: Categorical crossentropy
- **Evaluation**: Accuracy, sequence comparison

---

## ğŸ“ˆ EDA Insights

The notebook includes EDA visualizations such as:
- Distribution of word lengths
- Top prefixes and suffixes in root words
- Frequency of individual characters
- Word structure insights via scatter plots

---

## âœ¨ Example

**Input (misspelled):** `kmpiter`  
**Output (corrected):** `komputer`

---

## ğŸ“¬ Contact

**Alexander Tiopan**  
ğŸ“§ alexandertiopan1212@gmail.com  
ğŸŒ [GitHub](https://github.com/alexandertiopan1212)  
ğŸŒ [LinkedIn](https://www.linkedin.com/in/alexander-tiopan/)

---

## ğŸ“ License

This project is licensed under the MIT License â€” feel free to use, modify, and build upon it with attribution.
